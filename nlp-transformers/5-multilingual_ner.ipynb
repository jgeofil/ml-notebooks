{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jeremygf/git/ml-notebooks/.venv/lib/python3.11/site-packages/datasets/load.py:1429: FutureWarning: The repository for xtreme contains custom code which must be executed to correctly load the dataset. You can inspect the repository content at https://hf.co/datasets/xtreme\n",
      "You can avoid this message in future by passing the argument `trust_remote_code=True`.\n",
      "Passing `trust_remote_code=True` will be mandatory to load this dataset from the next major release of `datasets`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "XTREME has 183 configurations\n"
     ]
    }
   ],
   "source": [
    "from datasets import get_dataset_config_names\n",
    "\n",
    "xtreme_subsets = get_dataset_config_names(\"xtreme\")\n",
    "print(f\"XTREME has {len(xtreme_subsets)} configurations\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['XNLI', 'tydiqa', 'SQuAD', 'PAN-X.af', 'PAN-X.ar', 'PAN-X.bg', 'PAN-X.bn', 'PAN-X.de', 'PAN-X.el', 'PAN-X.en', 'PAN-X.es', 'PAN-X.et', 'PAN-X.eu', 'PAN-X.fa', 'PAN-X.fi', 'PAN-X.fr', 'PAN-X.he', 'PAN-X.hi', 'PAN-X.hu', 'PAN-X.id', 'PAN-X.it', 'PAN-X.ja', 'PAN-X.jv', 'PAN-X.ka', 'PAN-X.kk', 'PAN-X.ko', 'PAN-X.ml', 'PAN-X.mr', 'PAN-X.ms', 'PAN-X.my', 'PAN-X.nl', 'PAN-X.pt', 'PAN-X.ru', 'PAN-X.sw', 'PAN-X.ta', 'PAN-X.te', 'PAN-X.th', 'PAN-X.tl', 'PAN-X.tr', 'PAN-X.ur', 'PAN-X.vi', 'PAN-X.yo', 'PAN-X.zh', 'MLQA.ar.ar', 'MLQA.ar.de', 'MLQA.ar.vi', 'MLQA.ar.zh', 'MLQA.ar.en', 'MLQA.ar.es', 'MLQA.ar.hi', 'MLQA.de.ar', 'MLQA.de.de', 'MLQA.de.vi', 'MLQA.de.zh', 'MLQA.de.en', 'MLQA.de.es', 'MLQA.de.hi', 'MLQA.vi.ar', 'MLQA.vi.de', 'MLQA.vi.vi', 'MLQA.vi.zh', 'MLQA.vi.en', 'MLQA.vi.es', 'MLQA.vi.hi', 'MLQA.zh.ar', 'MLQA.zh.de', 'MLQA.zh.vi', 'MLQA.zh.zh', 'MLQA.zh.en', 'MLQA.zh.es', 'MLQA.zh.hi', 'MLQA.en.ar', 'MLQA.en.de', 'MLQA.en.vi', 'MLQA.en.zh', 'MLQA.en.en', 'MLQA.en.es', 'MLQA.en.hi', 'MLQA.es.ar', 'MLQA.es.de', 'MLQA.es.vi', 'MLQA.es.zh', 'MLQA.es.en', 'MLQA.es.es', 'MLQA.es.hi', 'MLQA.hi.ar', 'MLQA.hi.de', 'MLQA.hi.vi', 'MLQA.hi.zh', 'MLQA.hi.en', 'MLQA.hi.es', 'MLQA.hi.hi', 'XQuAD.ar', 'XQuAD.de', 'XQuAD.vi', 'XQuAD.zh', 'XQuAD.en', 'XQuAD.es', 'XQuAD.hi', 'XQuAD.el', 'XQuAD.ru', 'XQuAD.th', 'XQuAD.tr', 'bucc18.de', 'bucc18.fr', 'bucc18.zh', 'bucc18.ru', 'PAWS-X.de', 'PAWS-X.en', 'PAWS-X.es', 'PAWS-X.fr', 'PAWS-X.ja', 'PAWS-X.ko', 'PAWS-X.zh', 'tatoeba.afr', 'tatoeba.ara', 'tatoeba.ben', 'tatoeba.bul', 'tatoeba.deu', 'tatoeba.cmn', 'tatoeba.ell', 'tatoeba.est', 'tatoeba.eus', 'tatoeba.fin', 'tatoeba.fra', 'tatoeba.heb', 'tatoeba.hin', 'tatoeba.hun', 'tatoeba.ind', 'tatoeba.ita', 'tatoeba.jav', 'tatoeba.jpn', 'tatoeba.kat', 'tatoeba.kaz', 'tatoeba.kor', 'tatoeba.mal', 'tatoeba.mar', 'tatoeba.nld', 'tatoeba.pes', 'tatoeba.por', 'tatoeba.rus', 'tatoeba.spa', 'tatoeba.swh', 'tatoeba.tam', 'tatoeba.tel', 'tatoeba.tgl', 'tatoeba.tha', 'tatoeba.tur', 'tatoeba.urd', 'tatoeba.vie', 'udpos.Afrikaans', 'udpos.Arabic', 'udpos.Basque', 'udpos.Bulgarian', 'udpos.Dutch', 'udpos.English', 'udpos.Estonian', 'udpos.Finnish', 'udpos.French', 'udpos.German', 'udpos.Greek', 'udpos.Hebrew', 'udpos.Hindi', 'udpos.Hungarian', 'udpos.Indonesian', 'udpos.Italian', 'udpos.Japanese', 'udpos.Kazakh', 'udpos.Korean', 'udpos.Chinese', 'udpos.Marathi', 'udpos.Persian', 'udpos.Portuguese', 'udpos.Russian', 'udpos.Spanish', 'udpos.Tagalog', 'udpos.Tamil', 'udpos.Telugu', 'udpos.Thai', 'udpos.Turkish', 'udpos.Urdu', 'udpos.Vietnamese', 'udpos.Yoruba']\n"
     ]
    }
   ],
   "source": [
    "print(xtreme_subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "panx_subsets = [s for s in xtreme_subsets if s.startswith(\"PAN\")]\n",
    "len(panx_subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 20000\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['tokens', 'ner_tags', 'langs'],\n",
       "        num_rows: 10000\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "load_dataset(\"xtreme\", name=\"PAN-X.de\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<class 'datasets.dataset_dict.DatasetDict'>, {})\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "from datasets import DatasetDict\n",
    "\n",
    "langs = [\"de\", \"fr\", \"it\", \"en\"]\n",
    "fracs = [0.629, 0.229, 0.084, 0.059]\n",
    "# Return a DatasetDict if a key doesn't exist\n",
    "panx_ch = defaultdict(DatasetDict)\n",
    "print(panx_ch)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defaultdict(datasets.dataset_dict.DatasetDict,\n",
       "            {'de': DatasetDict({\n",
       "                 train: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 12580\n",
       "                 })\n",
       "                 validation: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 6290\n",
       "                 })\n",
       "                 test: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 6290\n",
       "                 })\n",
       "             }),\n",
       "             'fr': DatasetDict({\n",
       "                 train: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 4580\n",
       "                 })\n",
       "                 validation: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 2290\n",
       "                 })\n",
       "                 test: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 2290\n",
       "                 })\n",
       "             }),\n",
       "             'it': DatasetDict({\n",
       "                 train: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 1680\n",
       "                 })\n",
       "                 validation: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 840\n",
       "                 })\n",
       "                 test: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 840\n",
       "                 })\n",
       "             }),\n",
       "             'en': DatasetDict({\n",
       "                 train: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 1180\n",
       "                 })\n",
       "                 validation: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 590\n",
       "                 })\n",
       "                 test: Dataset({\n",
       "                     features: ['tokens', 'ner_tags', 'langs'],\n",
       "                     num_rows: 590\n",
       "                 })\n",
       "             })})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for lang, frac in zip(langs, fracs):\n",
    "    # Load monolingual corpus\n",
    "    ds = load_dataset(\"xtreme\", name=f\"PAN-X.{lang}\", trust_remote_code=True)\n",
    "    # Shuffle and downsample each split according to spoken proportion\n",
    "    for split in ds:\n",
    "        idx = range(int(frac * ds[split].num_rows))\n",
    "        panx_ch[lang][split] = ds[split].shuffle(seed=0).select(idx)\n",
    "        \n",
    "panx_ch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>de</th>\n",
       "      <th>fr</th>\n",
       "      <th>it</th>\n",
       "      <th>en</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Number of training examples</th>\n",
       "      <td>12580</td>\n",
       "      <td>4580</td>\n",
       "      <td>1680</td>\n",
       "      <td>1180</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                de    fr    it    en\n",
       "Number of training examples  12580  4580  1680  1180"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame({lang: [panx_ch[lang][\"train\"].num_rows] for lang in langs},\n",
    "             index=[\"Number of training examples\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: ['2.000', 'Einwohnern', 'an', 'der', 'Danziger', 'Bucht', 'in', 'der', 'polnischen', 'Woiwodschaft', 'Pommern', '.']\n",
      "ner_tags: [0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0]\n",
      "langs: ['de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de', 'de']\n"
     ]
    }
   ],
   "source": [
    "element = panx_ch[\"de\"][\"train\"][0]\n",
    "for key, value in element.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokens: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n",
      "ner_tags: Sequence(feature=ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None), length=-1, id=None)\n",
      "langs: Sequence(feature=Value(dtype='string', id=None), length=-1, id=None)\n"
     ]
    }
   ],
   "source": [
    "for key, value in panx_ch[\"de\"][\"train\"].features.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ClassLabel(names=['O', 'B-PER', 'I-PER', 'B-ORG', 'I-ORG', 'B-LOC', 'I-LOC'], id=None)\n"
     ]
    }
   ],
   "source": [
    "tags = panx_ch[\"de\"][\"train\"].features[\"ner_tags\"].feature\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_tag_names(batch):\n",
    "    return {\"ner_tags_str\": [tags.int2str(idx) for idx in batch[\"ner_tags\"]]}\n",
    "\n",
    "panx_de = panx_ch[\"de\"].map(create_tag_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>2.000</td>\n",
       "      <td>Einwohnern</td>\n",
       "      <td>an</td>\n",
       "      <td>der</td>\n",
       "      <td>Danziger</td>\n",
       "      <td>Bucht</td>\n",
       "      <td>in</td>\n",
       "      <td>der</td>\n",
       "      <td>polnischen</td>\n",
       "      <td>Woiwodschaft</td>\n",
       "      <td>Pommern</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0           1   2    3         4      5   6    7           8   \\\n",
       "Tokens  2.000  Einwohnern  an  der  Danziger  Bucht  in  der  polnischen   \n",
       "Tags        O           O   O    O     B-LOC  I-LOC   O    O       B-LOC   \n",
       "\n",
       "                  9        10 11  \n",
       "Tokens  Woiwodschaft  Pommern  .  \n",
       "Tags           B-LOC    I-LOC  O  "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "de_example = panx_de[\"train\"][0]\n",
    "pd.DataFrame([de_example[\"tokens\"], de_example[\"ner_tags_str\"]],\n",
    "['Tokens', 'Tags'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>O</th>\n",
       "      <th>B-LOC</th>\n",
       "      <th>I-LOC</th>\n",
       "      <th>B-ORG</th>\n",
       "      <th>I-ORG</th>\n",
       "      <th>B-PER</th>\n",
       "      <th>I-PER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>train</th>\n",
       "      <td>86792</td>\n",
       "      <td>6186</td>\n",
       "      <td>2964</td>\n",
       "      <td>5366</td>\n",
       "      <td>7663</td>\n",
       "      <td>5810</td>\n",
       "      <td>8265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>validation</th>\n",
       "      <td>43648</td>\n",
       "      <td>3172</td>\n",
       "      <td>1462</td>\n",
       "      <td>2683</td>\n",
       "      <td>3820</td>\n",
       "      <td>2893</td>\n",
       "      <td>4139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>test</th>\n",
       "      <td>43565</td>\n",
       "      <td>3180</td>\n",
       "      <td>1428</td>\n",
       "      <td>2573</td>\n",
       "      <td>3673</td>\n",
       "      <td>3071</td>\n",
       "      <td>4335</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                O  B-LOC  I-LOC  B-ORG  I-ORG  B-PER  I-PER\n",
       "train       86792   6186   2964   5366   7663   5810   8265\n",
       "validation  43648   3172   1462   2683   3820   2893   4139\n",
       "test        43565   3180   1428   2573   3673   3071   4335"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "split2freqs = defaultdict(Counter)\n",
    "for split, dataset in panx_de.items():\n",
    "    for row in dataset[\"ner_tags_str\"]:\n",
    "        for tag in row:\n",
    "            if tag:#.startswith(r\"B\"):\n",
    "                tag_type = tag#.split(\"-\")[1]\n",
    "                split2freqs[split][tag_type] += 1\n",
    "pd.DataFrame.from_dict(split2freqs, orient=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "bert_model_name = \"bert-base-cased\"\n",
    "xlmr_model_name = \"xlm-roberta-base\"\n",
    "bert_tokenizer = AutoTokenizer.from_pretrained(bert_model_name)\n",
    "xlmr_tokenizer = AutoTokenizer.from_pretrained(xlmr_model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Jack Sparrow loves New York!\"\n",
    "bert_tokens = bert_tokenizer(text).tokens()\n",
    "xlmr_tokens = xlmr_tokenizer(text).tokens()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['[CLS]', 'Jack', 'Spa', '##rrow', 'loves', 'New', 'York', '!', '[SEP]']"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bert_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['<s>', '▁Jack', '▁Spar', 'row', '▁love', 's', '▁New', '▁York', '!', '</s>']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xlmr_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from transformers import XLMRobertaConfig\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from transformers.models.roberta.modeling_roberta import RobertaModel\n",
    "from transformers.models.roberta.modeling_roberta import RobertaPreTrainedModel\n",
    "\n",
    "class XLMRobertaForTokenClassification(RobertaPreTrainedModel):\n",
    "    config_class = XLMRobertaConfig\n",
    "\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.num_labels = config.num_labels\n",
    "        # Load model body\n",
    "        self.roberta = RobertaModel(config, add_pooling_layer=False)\n",
    "        for param in self.roberta.encoder.parameters():\n",
    "            param.requires_grad = False\n",
    "        # Set up token classification head\n",
    "        self.dropout = nn.Dropout(config.hidden_dropout_prob)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        # Load and initialize weights\n",
    "        self.init_weights()\n",
    "\n",
    "    def forward(self, input_ids=None, attention_mask=None, token_type_ids=None,\n",
    "                labels=None, **kwargs):\n",
    "        # Use model body to get encoder representations\n",
    "        outputs = self.roberta(input_ids, attention_mask=attention_mask,\n",
    "                               token_type_ids=token_type_ids, **kwargs)\n",
    "        # Apply classifier to encoder representation\n",
    "        sequence_output = self.dropout(outputs[0])\n",
    "        logits = self.classifier(sequence_output)\n",
    "        # Calculate losses\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            loss_fct = nn.CrossEntropyLoss()\n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "        # Return model output object\n",
    "        return TokenClassifierOutput(loss=loss, logits=logits,\n",
    "                                     hidden_states=outputs.hidden_states,\n",
    "                                     attentions=outputs.attentions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "index2tag = {idx: tag for idx, tag in enumerate(tags.names)}\n",
    "tag2index = {tag: idx for idx, tag in enumerate(tags.names)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "xlmr_config = AutoConfig.from_pretrained(xlmr_model_name,\n",
    "                                         num_labels=tags.num_classes,\n",
    "                                         id2label=index2tag, label2id=tag2index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "xlmr_model = (XLMRobertaForTokenClassification\n",
    "              .from_pretrained(xlmr_model_name, config=xlmr_config)\n",
    "              .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jack</td>\n",
       "      <td>▁Spar</td>\n",
       "      <td>row</td>\n",
       "      <td>▁love</td>\n",
       "      <td>s</td>\n",
       "      <td>▁New</td>\n",
       "      <td>▁York</td>\n",
       "      <td>!</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Input IDs</th>\n",
       "      <td>0</td>\n",
       "      <td>21763</td>\n",
       "      <td>37456</td>\n",
       "      <td>15555</td>\n",
       "      <td>5161</td>\n",
       "      <td>7</td>\n",
       "      <td>2356</td>\n",
       "      <td>5753</td>\n",
       "      <td>38</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0      1      2      3      4  5     6      7   8     9\n",
       "Tokens     <s>  ▁Jack  ▁Spar    row  ▁love  s  ▁New  ▁York   !  </s>\n",
       "Input IDs    0  21763  37456  15555   5161  7  2356   5753  38     2"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_ids = xlmr_tokenizer.encode(text, return_tensors=\"pt\")\n",
    "pd.DataFrame([xlmr_tokens, input_ids[0].numpy()], index=[\"Tokens\", \"Input IDs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of tokens in sequence: 10\n",
      "Shape of outputs: torch.Size([1, 10, 7])\n"
     ]
    }
   ],
   "source": [
    "outputs = xlmr_model(input_ids.to(device)).logits\n",
    "predictions = torch.argmax(outputs, dim=-1)\n",
    "print(f\"Number of tokens in sequence: {len(xlmr_tokens)}\")\n",
    "print(f\"Shape of outputs: {outputs.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jack</td>\n",
       "      <td>▁Spar</td>\n",
       "      <td>row</td>\n",
       "      <td>▁love</td>\n",
       "      <td>s</td>\n",
       "      <td>▁New</td>\n",
       "      <td>▁York</td>\n",
       "      <td>!</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0      1      2      3      4      5      6      7      8      9\n",
       "Tokens    <s>  ▁Jack  ▁Spar    row  ▁love      s   ▁New  ▁York      !   </s>\n",
       "Tags    I-ORG  I-ORG  I-ORG  I-ORG  B-LOC  B-LOC  I-ORG  I-ORG  I-ORG  I-ORG"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    "pd.DataFrame([xlmr_tokens, preds], index=[\"Tokens\", \"Tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tag_text(text, tags, model, tokenizer):\n",
    "    # Get tokens with special characters\n",
    "    tokens = tokenizer(text).tokens()\n",
    "    # Encode the sequence into IDs\n",
    "    input_ids = xlmr_tokenizer(text, return_tensors=\"pt\").input_ids.to(device)\n",
    "    # Get predictions as distribution over 7 possible classes\n",
    "    outputs = model(input_ids)[0]\n",
    "    # Take argmax to get most likely class per token\n",
    "    predictions = torch.argmax(outputs, dim=2)\n",
    "    # Convert to DataFrame\n",
    "    preds = [tags.names[p] for p in predictions[0].cpu().numpy()]\n",
    "    return pd.DataFrame([tokens, preds], index=[\"Tokens\", \"Tags\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2.000', 'Einwohnern', 'an', 'der', 'Danziger', 'Bucht', 'in', 'der', 'polnischen', 'Woiwodschaft', 'Pommern', '.']\n",
      "[0, 0, 0, 0, 5, 6, 0, 0, 5, 5, 6, 0]\n"
     ]
    }
   ],
   "source": [
    "words, labels = de_example[\"tokens\"], de_example[\"ner_tags\"]\n",
    "print(words)\n",
    "print(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>IDs</th>\n",
       "      <td>0</td>\n",
       "      <td>70101</td>\n",
       "      <td>176581</td>\n",
       "      <td>19</td>\n",
       "      <td>142</td>\n",
       "      <td>122</td>\n",
       "      <td>2290</td>\n",
       "      <td>708</td>\n",
       "      <td>1505</td>\n",
       "      <td>18363</td>\n",
       "      <td>...</td>\n",
       "      <td>13787</td>\n",
       "      <td>14</td>\n",
       "      <td>15263</td>\n",
       "      <td>18917</td>\n",
       "      <td>663</td>\n",
       "      <td>6947</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0       1           2   3    4     5     6    7     8      9   ...  \\\n",
       "IDs       0   70101      176581  19  142   122  2290  708  1505  18363  ...   \n",
       "Tokens  <s>  ▁2.000  ▁Einwohner   n  ▁an  ▁der  ▁Dan   zi   ger  ▁Buch  ...   \n",
       "\n",
       "           15  16     17      18   19    20  21 22 23    24  \n",
       "IDs     13787  14  15263   18917  663  6947  19  6  5     2  \n",
       "Tokens    ▁Wo   i    wod  schaft  ▁Po  mmer   n  ▁  .  </s>  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_input = xlmr_tokenizer(de_example[\"tokens\"], is_split_into_words=True)\n",
    "tokens = xlmr_tokenizer.convert_ids_to_tokens(tokenized_input[\"input_ids\"])\n",
    "pd.DataFrame([tokenized_input[\"input_ids\"], tokens], index=[\"IDs\", \"Tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word IDs</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0       1           2  3    4     5     6   7    8      9   ...  \\\n",
       "Tokens     <s>  ▁2.000  ▁Einwohner  n  ▁an  ▁der  ▁Dan  zi  ger  ▁Buch  ...   \n",
       "Word IDs  None       0           1  1    2     3     4   4    4      5  ...   \n",
       "\n",
       "           15 16   17      18   19    20  21  22  23    24  \n",
       "Tokens    ▁Wo  i  wod  schaft  ▁Po  mmer   n   ▁   .  </s>  \n",
       "Word IDs    9  9    9       9   10    10  10  11  11  None  \n",
       "\n",
       "[2 rows x 25 columns]"
      ]
     },
     "execution_count": 208,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_ids = tokenized_input.word_ids()\n",
    "pd.DataFrame([tokens, word_ids], index=[\"Tokens\", \"Word IDs\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁2.000</td>\n",
       "      <td>▁Einwohner</td>\n",
       "      <td>n</td>\n",
       "      <td>▁an</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁Dan</td>\n",
       "      <td>zi</td>\n",
       "      <td>ger</td>\n",
       "      <td>▁Buch</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Wo</td>\n",
       "      <td>i</td>\n",
       "      <td>wod</td>\n",
       "      <td>schaft</td>\n",
       "      <td>▁Po</td>\n",
       "      <td>mmer</td>\n",
       "      <td>n</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Word IDs</th>\n",
       "      <td>None</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>...</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Label IDs</th>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>6</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "      <td>0</td>\n",
       "      <td>-100</td>\n",
       "      <td>-100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Labels</th>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>...</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0       1           2     3    4     5      6     7     8   \\\n",
       "Tokens      <s>  ▁2.000  ▁Einwohner     n  ▁an  ▁der   ▁Dan    zi   ger   \n",
       "Word IDs   None       0           1     1    2     3      4     4     4   \n",
       "Label IDs  -100       0           0  -100    0     0      5  -100  -100   \n",
       "Labels      IGN       O           O   IGN    O     O  B-LOC   IGN   IGN   \n",
       "\n",
       "              9   ...     15    16    17      18     19    20    21  22    23  \\\n",
       "Tokens     ▁Buch  ...    ▁Wo     i   wod  schaft    ▁Po  mmer     n   ▁     .   \n",
       "Word IDs       5  ...      9     9     9       9     10    10    10  11    11   \n",
       "Label IDs      6  ...      5  -100  -100    -100      6  -100  -100   0  -100   \n",
       "Labels     I-LOC  ...  B-LOC   IGN   IGN     IGN  I-LOC   IGN   IGN   O   IGN   \n",
       "\n",
       "             24  \n",
       "Tokens     </s>  \n",
       "Word IDs   None  \n",
       "Label IDs  -100  \n",
       "Labels      IGN  \n",
       "\n",
       "[4 rows x 25 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_word_idx = None\n",
    "label_ids = []\n",
    "\n",
    "for word_idx in word_ids:\n",
    "    if word_idx is None or word_idx == previous_word_idx:\n",
    "        label_ids.append(-100)\n",
    "    elif word_idx != previous_word_idx:\n",
    "        label_ids.append(labels[word_idx])\n",
    "    previous_word_idx = word_idx\n",
    "\n",
    "labels = [index2tag[l] if l != -100 else \"IGN\" for l in label_ids]\n",
    "index = [\"Tokens\", \"Word IDs\", \"Label IDs\", \"Labels\"]\n",
    "\n",
    "pd.DataFrame([tokens, word_ids, label_ids, labels], index=index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = xlmr_tokenizer(examples[\"tokens\"], truncation=True,\n",
    "                                      is_split_into_words=True)\n",
    "    labels = []\n",
    "    for idx, label in enumerate(examples[\"ner_tags\"]):\n",
    "        word_ids = tokenized_inputs.word_ids(batch_index=idx)\n",
    "        previous_word_idx = None\n",
    "        label_ids = []\n",
    "        for word_idx in word_ids:\n",
    "            if word_idx is None or word_idx == previous_word_idx:\n",
    "                label_ids.append(-100)\n",
    "            else:\n",
    "                label_ids.append(label[word_idx])\n",
    "            previous_word_idx = word_idx\n",
    "        labels.append(label_ids)\n",
    "    tokenized_inputs[\"labels\"] = labels\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def encode_panx_dataset(corpus):\n",
    "    return corpus.map(tokenize_and_align_labels, batched=True,\n",
    "                      remove_columns=['langs', 'ner_tags', 'tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "panx_de_encoded = encode_panx_dataset(panx_ch[\"de\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "        MISC       0.00      0.00      0.00         1\n",
      "         PER       1.00      1.00      1.00         1\n",
      "\n",
      "   micro avg       0.50      0.50      0.50         2\n",
      "   macro avg       0.50      0.50      0.50         2\n",
      "weighted avg       0.50      0.50      0.50         2\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from seqeval.metrics import classification_report\n",
    "\n",
    "y_true = [[\"O\", \"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
    "          [\"B-PER\", \"I-PER\", \"O\"]]\n",
    "y_pred = [[\"O\", \"O\", \"B-MISC\", \"I-MISC\", \"I-MISC\", \"I-MISC\", \"O\"],\n",
    "          [\"B-PER\", \"I-PER\", \"O\"]]\n",
    "print(classification_report(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def align_predictions(predictions, label_ids):\n",
    "    preds = np.argmax(predictions, axis=2)\n",
    "    batch_size, seq_len = preds.shape\n",
    "    labels_list, preds_list = [], []\n",
    "\n",
    "    for batch_idx in range(batch_size):\n",
    "        example_labels, example_preds = [], []\n",
    "        for seq_idx in range(seq_len):\n",
    "            # Ignore label IDs = -100\n",
    "            if label_ids[batch_idx, seq_idx] != -100:\n",
    "                example_labels.append(index2tag[label_ids[batch_idx][seq_idx]])\n",
    "                example_preds.append(index2tag[preds[batch_idx][seq_idx]])\n",
    "\n",
    "        labels_list.append(example_labels)\n",
    "        preds_list.append(example_preds)\n",
    "\n",
    "    return preds_list, labels_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "num_epochs = 3\n",
    "batch_size = 24\n",
    "logging_steps = len(panx_de_encoded[\"train\"]) // batch_size\n",
    "model_name = f\"{xlmr_model_name}-headtuned-panx-de\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=model_name, log_level=\"error\", num_train_epochs=num_epochs,\n",
    "    per_device_train_batch_size=batch_size,\n",
    "    per_device_eval_batch_size=batch_size, evaluation_strategy=\"epoch\",\n",
    "    save_steps=1e6, weight_decay=0.01, disable_tqdm=False,\n",
    "    logging_steps=logging_steps, push_to_hub=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81f0987d91074f45915a918f6327d371",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from huggingface_hub import notebook_login\n",
    "\n",
    "notebook_login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import f1_score\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    y_pred, y_true = align_predictions(eval_pred.predictions,\n",
    "                                       eval_pred.label_ids)\n",
    "    return {\"f1\": f1_score(y_true, y_pred)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_init():\n",
    "    return (XLMRobertaForTokenClassification\n",
    "            .from_pretrained(xlmr_model_name, config=xlmr_config)\n",
    "            .to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import Trainer\n",
    "\n",
    "trainer = Trainer(model_init=model_init, args=training_args,\n",
    "                  data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "                  train_dataset=panx_de_encoded[\"train\"],\n",
    "                  eval_dataset=panx_de_encoded[\"validation\"],\n",
    "                  tokenizer=xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='703' max='1575' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 703/1575 17:00 < 21:09, 0.69 it/s, Epoch 1.34/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.283800</td>\n",
       "      <td>0.954657</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[219], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m trainer\u001b[38;5;241m.\u001b[39mpush_to_hub(commit_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/git/ml-notebooks/.venv/lib/python3.11/site-packages/transformers/trainer.py:1528\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1526\u001b[0m     \u001b[38;5;66;03m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[39;00m\n\u001b[1;32m   1527\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39mdisable_progress_bars()\n\u001b[0;32m-> 1528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1535\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n",
      "File \u001b[0;32m~/git/ml-notebooks/.venv/lib/python3.11/site-packages/transformers/trainer.py:1821\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1818\u001b[0m     rng_to_sync \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1820\u001b[0m step \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m\n\u001b[0;32m-> 1821\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mstep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mepoch_iterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1822\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtotal_batched_samples\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\n\u001b[1;32m   1824\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minclude_num_input_tokens_seen\u001b[49m\u001b[43m:\u001b[49m\n",
      "File \u001b[0;32m~/git/ml-notebooks/.venv/lib/python3.11/site-packages/accelerate/data_loader.py:457\u001b[0m, in \u001b[0;36mDataLoaderShard.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    455\u001b[0m     \u001b[38;5;66;03m# But we still move it to the device so it is done before `StopIteration` is reached\u001b[39;00m\n\u001b[1;32m    456\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 457\u001b[0m         current_batch \u001b[38;5;241m=\u001b[39m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcurrent_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    458\u001b[0m     next_batch \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataloader_iter)\n\u001b[1;32m    459\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m batch_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mskip_batches:\n",
      "File \u001b[0;32m~/git/ml-notebooks/.venv/lib/python3.11/site-packages/accelerate/utils/operations.py:161\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m skip_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m         skip_keys \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensor)(\n\u001b[0;32m--> 161\u001b[0m         \u001b[43m{\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m            \u001b[49m\u001b[43mk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mitems\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    165\u001b[0m     )\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/git/ml-notebooks/.venv/lib/python3.11/site-packages/accelerate/utils/operations.py:162\u001b[0m, in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01melif\u001b[39;00m skip_keys \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    159\u001b[0m         skip_keys \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    160\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(tensor)(\n\u001b[1;32m    161\u001b[0m         {\n\u001b[0;32m--> 162\u001b[0m             k: t \u001b[38;5;28;01mif\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m skip_keys \u001b[38;5;28;01melse\u001b[39;00m \u001b[43msend_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mskip_keys\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    163\u001b[0m             \u001b[38;5;28;01mfor\u001b[39;00m k, t \u001b[38;5;129;01min\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    164\u001b[0m         }\n\u001b[1;32m    165\u001b[0m     )\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/git/ml-notebooks/.venv/lib/python3.11/site-packages/accelerate/utils/operations.py:168\u001b[0m, in \u001b[0;36msend_to_device\u001b[0;34m(tensor, device, non_blocking, skip_keys)\u001b[0m\n\u001b[1;32m    166\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(tensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    167\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 168\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:  \u001b[38;5;66;03m# .to() doesn't accept non_blocking as kwarg\u001b[39;00m\n\u001b[1;32m    170\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m tensor\u001b[38;5;241m.\u001b[39mto(device)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "trainer.push_to_hub(commit_message=\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jeff</td>\n",
       "      <td>▁De</td>\n",
       "      <td>an</td>\n",
       "      <td>▁ist</td>\n",
       "      <td>▁ein</td>\n",
       "      <td>▁Informati</td>\n",
       "      <td>ker</td>\n",
       "      <td>▁bei</td>\n",
       "      <td>▁Google</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁Kaliforni</td>\n",
       "      <td>en</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1    2   3     4     5           6    7     8        9    10  \\\n",
       "Tokens  <s>  ▁Jeff  ▁De  an  ▁ist  ▁ein  ▁Informati  ker  ▁bei  ▁Google  ▁in   \n",
       "Tags      O      O    O   O     O     O           O    O     O        O    O   \n",
       "\n",
       "                11  12    13  \n",
       "Tokens  ▁Kaliforni  en  </s>  \n",
       "Tags             O   O     O  "
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_de = \"Jeff Dean ist ein Informatiker bei Google in Kalifornien\"\n",
    "tag_text(text_de, tags, trainer.model, xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.functional import cross_entropy\n",
    "\n",
    "def forward_pass_with_label(batch):\n",
    "    # Convert dict of lists to list of dicts suitable for data collator\n",
    "    features = [dict(zip(batch, t)) for t in zip(*batch.values())]\n",
    "    # Pad inputs and labels and put all tensors on device\n",
    "    batch = data_collator(features)\n",
    "    input_ids = batch[\"input_ids\"].to(device)\n",
    "    attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels = batch[\"labels\"].to(device)\n",
    "    with torch.no_grad():\n",
    "        # Pass data through model\n",
    "        output = trainer.model(input_ids, attention_mask)\n",
    "        # logit.size: [batch_size, sequence_length, classes]\n",
    "        # Predict class with largest logit value on classes axis\n",
    "        predicted_label = torch.argmax(output.logits, axis=-1).cpu().numpy()\n",
    "    # Calculate loss per token after flattening batch dimension with view\n",
    "    loss = cross_entropy(output.logits.view(-1, 7),\n",
    "                         labels.view(-1), reduction=\"none\")\n",
    "    # Unflatten batch dimension and convert to numpy array\n",
    "    loss = loss.view(len(input_ids), -1).cpu().numpy()\n",
    "\n",
    "    return {\"loss\":loss, \"predicted_label\": predicted_label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b06a9fe58e94d3aae0a6dbb4b2645af",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/6290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "valid_set = panx_de_encoded[\"validation\"]\n",
    "valid_set = valid_set.map(forward_pass_with_label, batched=True, batch_size=32)\n",
    "df = valid_set.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[0, 10699, 11, 15, 16104, 1388, 2]</td>\n",
       "      <td>[1, 1, 1, 1, 1, 1, 1]</td>\n",
       "      <td>[IGN, B-ORG, IGN, I-ORG, I-ORG, I-ORG, IGN]</td>\n",
       "      <td>[0.0, 2.565156, 0.0, 2.6149352, 2.3301773, 2.6...</td>\n",
       "      <td>[O, O, O, O, O, O, O]</td>\n",
       "      <td>[&lt;s&gt;, ▁Ham, a, ▁(, ▁Unternehmen, ▁), &lt;/s&gt;]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                            input_ids         attention_mask  \\\n",
       "0  [0, 10699, 11, 15, 16104, 1388, 2]  [1, 1, 1, 1, 1, 1, 1]   \n",
       "\n",
       "                                        labels  \\\n",
       "0  [IGN, B-ORG, IGN, I-ORG, I-ORG, I-ORG, IGN]   \n",
       "\n",
       "                                                loss        predicted_label  \\\n",
       "0  [0.0, 2.565156, 0.0, 2.6149352, 2.3301773, 2.6...  [O, O, O, O, O, O, O]   \n",
       "\n",
       "                                 input_tokens  \n",
       "0  [<s>, ▁Ham, a, ▁(, ▁Unternehmen, ▁), </s>]  "
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index2tag[-100] = \"IGN\"\n",
    "df[\"input_tokens\"] = df[\"input_ids\"].apply(\n",
    "    lambda x: xlmr_tokenizer.convert_ids_to_tokens(x))\n",
    "df[\"predicted_label\"] = df[\"predicted_label\"].apply(\n",
    "    lambda x: [index2tag[i] for i in x])\n",
    "df[\"labels\"] = df[\"labels\"].apply(\n",
    "    lambda x: [index2tag[i] for i in x])\n",
    "df['loss'] = df.apply(\n",
    "    lambda x: x['loss'][:len(x['input_ids'])], axis=1)\n",
    "df['predicted_label'] = df.apply(\n",
    "    lambda x: x['predicted_label'][:len(x['input_ids'])], axis=1)\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>input_ids</th>\n",
       "      <th>attention_mask</th>\n",
       "      <th>labels</th>\n",
       "      <th>loss</th>\n",
       "      <th>predicted_label</th>\n",
       "      <th>input_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10699</td>\n",
       "      <td>1</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>2.57</td>\n",
       "      <td>O</td>\n",
       "      <td>▁Ham</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>2.61</td>\n",
       "      <td>O</td>\n",
       "      <td>▁(</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16104</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>2.33</td>\n",
       "      <td>O</td>\n",
       "      <td>▁Unternehmen</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1388</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>2.61</td>\n",
       "      <td>O</td>\n",
       "      <td>▁)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>56530</td>\n",
       "      <td>1</td>\n",
       "      <td>O</td>\n",
       "      <td>0.56</td>\n",
       "      <td>O</td>\n",
       "      <td>▁WE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83982</td>\n",
       "      <td>1</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>2.63</td>\n",
       "      <td>O</td>\n",
       "      <td>▁Luz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>2.61</td>\n",
       "      <td>O</td>\n",
       "      <td>▁a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  input_ids attention_mask labels  loss predicted_label  input_tokens\n",
       "0     10699              1  B-ORG  2.57               O          ▁Ham\n",
       "0        15              1  I-ORG  2.61               O            ▁(\n",
       "0     16104              1  I-ORG  2.33               O  ▁Unternehmen\n",
       "0      1388              1  I-ORG  2.61               O            ▁)\n",
       "1     56530              1      O  0.56               O           ▁WE\n",
       "1     83982              1  B-ORG  2.63               O          ▁Luz\n",
       "1        10              1  I-ORG  2.61               O            ▁a"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tokens = df.apply(pd.Series.explode)\n",
    "df_tokens = df_tokens.query(\"labels != 'IGN'\")\n",
    "df_tokens[\"loss\"] = df_tokens[\"loss\"].astype(float).round(2)\n",
    "df_tokens.head(7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>input_tokens</th>\n",
       "      <td>▁</td>\n",
       "      <td>▁''</td>\n",
       "      <td>▁)</td>\n",
       "      <td>▁(</td>\n",
       "      <td>▁'</td>\n",
       "      <td>▁von</td>\n",
       "      <td>▁der</td>\n",
       "      <td>▁in</td>\n",
       "      <td>▁und</td>\n",
       "      <td>▁de</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>6066</td>\n",
       "      <td>2898</td>\n",
       "      <td>246</td>\n",
       "      <td>246</td>\n",
       "      <td>2133</td>\n",
       "      <td>808</td>\n",
       "      <td>1388</td>\n",
       "      <td>989</td>\n",
       "      <td>1171</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2.89</td>\n",
       "      <td>2.85</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>2253.98</td>\n",
       "      <td>915.57</td>\n",
       "      <td>710.07</td>\n",
       "      <td>702.2</td>\n",
       "      <td>677.89</td>\n",
       "      <td>631.23</td>\n",
       "      <td>537.35</td>\n",
       "      <td>338.69</td>\n",
       "      <td>328.69</td>\n",
       "      <td>326.46</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0       1       2      3       4       5       6       7  \\\n",
       "input_tokens        ▁     ▁''      ▁)     ▁(      ▁'    ▁von    ▁der     ▁in   \n",
       "count            6066    2898     246    246    2133     808    1388     989   \n",
       "mean             0.37    0.32    2.89   2.85    0.32    0.78    0.39    0.34   \n",
       "sum           2253.98  915.57  710.07  702.2  677.89  631.23  537.35  338.69   \n",
       "\n",
       "                   8       9  \n",
       "input_tokens    ▁und     ▁de  \n",
       "count           1171     139  \n",
       "mean            0.28    2.35  \n",
       "sum           328.69  326.46  "
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_tokens.groupby(\"input_tokens\")[[\"loss\"]]\n",
    "    .agg([\"count\", \"mean\", \"sum\"])\n",
    "    .droplevel(level=0, axis=1)  # Get rid of multi-level columns\n",
    "    .sort_values(by=\"sum\", ascending=False)\n",
    "    .reset_index()\n",
    "    .round(2)\n",
    "    .head(10)\n",
    "    .T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>input_tokens</th>\n",
       "      <td>▁Januar</td>\n",
       "      <td>▁dei</td>\n",
       "      <td>▁Freude</td>\n",
       "      <td>▁län</td>\n",
       "      <td>▁fach</td>\n",
       "      <td>▁wirksam</td>\n",
       "      <td>▁ä</td>\n",
       "      <td>▁inter</td>\n",
       "      <td>▁Alte</td>\n",
       "      <td>▁Bundesrepublik</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.91</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.24</td>\n",
       "      <td>3.23</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>7.82</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.27</td>\n",
       "      <td>3.26</td>\n",
       "      <td>3.24</td>\n",
       "      <td>3.23</td>\n",
       "      <td>3.21</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.19</td>\n",
       "      <td>3.18</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0     1        2     3      4         5     6       7  \\\n",
       "input_tokens  ▁Januar  ▁dei  ▁Freude  ▁län  ▁fach  ▁wirksam    ▁ä  ▁inter   \n",
       "count               2     1        1     1      1         1     1       1   \n",
       "mean             3.91   3.6     3.27  3.26   3.24      3.23  3.21    3.19   \n",
       "sum              7.82   3.6     3.27  3.26   3.24      3.23  3.21    3.19   \n",
       "\n",
       "                  8                9  \n",
       "input_tokens  ▁Alte  ▁Bundesrepublik  \n",
       "count             1                1  \n",
       "mean           3.19             3.18  \n",
       "sum            3.19             3.18  "
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(df_tokens.groupby(\"input_tokens\")[[\"loss\"]]\n",
    "    .agg([\"count\", \"mean\", \"sum\"])\n",
    "    .droplevel(level=0, axis=1)  # Get rid of multi-level columns\n",
    "    .sort_values(by=\"mean\", ascending=False)\n",
    "    .reset_index()\n",
    "    .round(2)\n",
    "    .head(10)\n",
    "    .T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>I-LOC</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>B-LOC</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1462</td>\n",
       "      <td>2683</td>\n",
       "      <td>3172</td>\n",
       "      <td>3820</td>\n",
       "      <td>2893</td>\n",
       "      <td>4139</td>\n",
       "      <td>43648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2.99</td>\n",
       "      <td>2.75</td>\n",
       "      <td>2.51</td>\n",
       "      <td>2.46</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sum</th>\n",
       "      <td>4368.51</td>\n",
       "      <td>7364.97</td>\n",
       "      <td>7975.22</td>\n",
       "      <td>9382.4</td>\n",
       "      <td>6814.19</td>\n",
       "      <td>8784.95</td>\n",
       "      <td>11910.39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              0        1        2       3        4        5         6\n",
       "labels    I-LOC    B-ORG    B-LOC   I-ORG    B-PER    I-PER         O\n",
       "count      1462     2683     3172    3820     2893     4139     43648\n",
       "mean       2.99     2.75     2.51    2.46     2.36     2.12      0.27\n",
       "sum     4368.51  7364.97  7975.22  9382.4  6814.19  8784.95  11910.39"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(\n",
    "    df_tokens.groupby(\"labels\")[[\"loss\"]]\n",
    "    .agg([\"count\", \"mean\", \"sum\"])\n",
    "    .droplevel(level=0, axis=1)\n",
    "    .sort_values(by=\"mean\", ascending=False)\n",
    "    .reset_index()\n",
    "    .round(2)\n",
    "    .T\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 600x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay, confusion_matrix\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "def plot_confusion_matrix(y_preds, y_true, labels):\n",
    "    cm = confusion_matrix(y_true, y_preds, normalize=\"true\")\n",
    "    fig, ax = plt.subplots(figsize=(6, 6))\n",
    "    disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=labels)\n",
    "    disp.plot(cmap=\"Blues\", values_format=\".2f\", ax=ax, colorbar=False)\n",
    "    plt.title(\"Normalized confusion matrix\")\n",
    "    plt.show()\n",
    "plot_confusion_matrix(df_tokens[\"labels\"], df_tokens[\"predicted_label\"],\n",
    "                      tags.names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁Sie</td>\n",
       "      <td>▁ist</td>\n",
       "      <td>▁Sitz</td>\n",
       "      <td>▁des</td>\n",
       "      <td>▁Europäische</td>\n",
       "      <td>n</td>\n",
       "      <td>▁Gericht</td>\n",
       "      <td>sho</td>\n",
       "      <td>fes</td>\n",
       "      <td>▁(</td>\n",
       "      <td>...</td>\n",
       "      <td>fa</td>\n",
       "      <td>zil</td>\n",
       "      <td>ität</td>\n",
       "      <td>▁(</td>\n",
       "      <td>▁EF</td>\n",
       "      <td>SF</td>\n",
       "      <td>▁)</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>...</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.82</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.03</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.98</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 76 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0     1      2     3             4     5         6     7     8   \\\n",
       "tokens  ▁Sie  ▁ist  ▁Sitz  ▁des  ▁Europäische     n  ▁Gericht   sho   fes   \n",
       "labels     O     O      O     O         B-ORG   IGN     I-ORG   IGN   IGN   \n",
       "preds      O     O      O     O             O     O         O     O     O   \n",
       "losses  0.27  0.16   0.31  0.13          2.82  0.00      2.46  0.00  0.00   \n",
       "\n",
       "           9   ...    66    67    68     69     70    71     72    73    74  \\\n",
       "tokens     ▁(  ...    fa   zil  ität     ▁(    ▁EF    SF     ▁)     ▁     .   \n",
       "labels  I-ORG  ...   IGN   IGN   IGN  I-ORG  I-ORG   IGN  I-ORG     O   IGN   \n",
       "preds       O  ...     O     O     O      O      O     O      O     O     O   \n",
       "losses   3.03  ...  0.00  0.00  0.00   2.98   2.40  0.00   3.33  0.09  0.00   \n",
       "\n",
       "          75  \n",
       "tokens  </s>  \n",
       "labels   IGN  \n",
       "preds      O  \n",
       "losses  0.00  \n",
       "\n",
       "[4 rows x 76 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>64</th>\n",
       "      <th>65</th>\n",
       "      <th>66</th>\n",
       "      <th>67</th>\n",
       "      <th>68</th>\n",
       "      <th>69</th>\n",
       "      <th>70</th>\n",
       "      <th>71</th>\n",
       "      <th>72</th>\n",
       "      <th>73</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁Dabei</td>\n",
       "      <td>▁spielt</td>\n",
       "      <td>e</td>\n",
       "      <td>▁die</td>\n",
       "      <td>▁Gruppe</td>\n",
       "      <td>▁mit</td>\n",
       "      <td>▁Band</td>\n",
       "      <td>s</td>\n",
       "      <td>▁wie</td>\n",
       "      <td>▁Pier</td>\n",
       "      <td>...</td>\n",
       "      <td>▁Ghost</td>\n",
       "      <td>▁Inside</td>\n",
       "      <td>▁und</td>\n",
       "      <td>▁A</td>\n",
       "      <td>▁Day</td>\n",
       "      <td>▁to</td>\n",
       "      <td>▁Remember</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>...</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>B-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>0.42</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.74</td>\n",
       "      <td>...</td>\n",
       "      <td>2.12</td>\n",
       "      <td>2.17</td>\n",
       "      <td>0.27</td>\n",
       "      <td>3.02</td>\n",
       "      <td>2.39</td>\n",
       "      <td>2.68</td>\n",
       "      <td>2.34</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 74 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0        1     2     3        4     5      6     7     8      9   \\\n",
       "tokens  ▁Dabei  ▁spielt     e  ▁die  ▁Gruppe  ▁mit  ▁Band     s  ▁wie  ▁Pier   \n",
       "labels       O        O   IGN     O        O     O      O   IGN     O  B-ORG   \n",
       "preds        O        O     O     O        O     O      O     O     O      O   \n",
       "losses    0.42     0.27  0.00  0.10     0.39  0.19   0.46  0.00  0.26   2.74   \n",
       "\n",
       "        ...      64       65    66     67     68     69         70    71  \\\n",
       "tokens  ...  ▁Ghost  ▁Inside  ▁und     ▁A   ▁Day    ▁to  ▁Remember     ▁   \n",
       "labels  ...   I-ORG    I-ORG     O  B-ORG  I-ORG  I-ORG      I-ORG     O   \n",
       "preds   ...       O        O     O      O      O      O          O     O   \n",
       "losses  ...    2.12     2.17  0.27   3.02   2.39   2.68       2.34  0.20   \n",
       "\n",
       "          72    73  \n",
       "tokens     .  </s>  \n",
       "labels   IGN   IGN  \n",
       "preds      O     O  \n",
       "losses  0.00  0.00  \n",
       "\n",
       "[4 rows x 74 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>84</th>\n",
       "      <th>85</th>\n",
       "      <th>86</th>\n",
       "      <th>87</th>\n",
       "      <th>88</th>\n",
       "      <th>89</th>\n",
       "      <th>90</th>\n",
       "      <th>91</th>\n",
       "      <th>92</th>\n",
       "      <th>93</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁Weitere</td>\n",
       "      <td>▁Version</td>\n",
       "      <td>en</td>\n",
       "      <td>▁exist</td>\n",
       "      <td>ieren</td>\n",
       "      <td>▁von</td>\n",
       "      <td>▁Sid</td>\n",
       "      <td>ney</td>\n",
       "      <td>▁Be</td>\n",
       "      <td>chet</td>\n",
       "      <td>...</td>\n",
       "      <td>spo</td>\n",
       "      <td>on</td>\n",
       "      <td>▁und</td>\n",
       "      <td>▁Co</td>\n",
       "      <td>o</td>\n",
       "      <td>tie</td>\n",
       "      <td>▁Williams</td>\n",
       "      <td>▁</td>\n",
       "      <td>.</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>...</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>O</td>\n",
       "      <td>B-PER</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-PER</td>\n",
       "      <td>O</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>...</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>0.37</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.32</td>\n",
       "      <td>2.28</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.26</td>\n",
       "      <td>2.26</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.12</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              0         1     2       3      4     5      6     7      8   \\\n",
       "tokens  ▁Weitere  ▁Version    en  ▁exist  ieren  ▁von   ▁Sid   ney    ▁Be   \n",
       "labels         O         O   IGN       O    IGN     O  B-PER   IGN  I-PER   \n",
       "preds          O         O     O       O      O     O      O     O      O   \n",
       "losses      0.37      0.46  0.00    0.46   0.00  0.32   2.28  0.00   2.09   \n",
       "\n",
       "          9   ...    84    85    86     87    88    89         90    91    92  \\\n",
       "tokens  chet  ...   spo    on  ▁und    ▁Co     o   tie  ▁Williams     ▁     .   \n",
       "labels   IGN  ...   IGN   IGN     O  B-PER   IGN   IGN      I-PER     O   IGN   \n",
       "preds      O  ...     O     O     O      O     O     O          O     O     O   \n",
       "losses  0.00  ...  0.00  0.00  0.26   2.26  0.00  0.00       2.12  0.20  0.00   \n",
       "\n",
       "          93  \n",
       "tokens  </s>  \n",
       "labels   IGN  \n",
       "preds      O  \n",
       "losses  0.00  \n",
       "\n",
       "[4 rows x 94 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def get_samples(df):\n",
    "    for _, row in df.iterrows():\n",
    "        labels, preds, tokens, losses = [], [], [], []\n",
    "        for i, mask in enumerate(row[\"attention_mask\"]):\n",
    "            if i not in {0, len(row[\"attention_mask\"])}:\n",
    "                labels.append(row[\"labels\"][i])\n",
    "                preds.append(row[\"predicted_label\"][i])\n",
    "                tokens.append(row[\"input_tokens\"][i])\n",
    "                losses.append(f\"{row['loss'][i]:.2f}\")\n",
    "        df_tmp = pd.DataFrame({\"tokens\": tokens, \"labels\": labels,\n",
    "                               \"preds\": preds, \"losses\": losses}).T\n",
    "        yield df_tmp\n",
    "\n",
    "df[\"total_loss\"] = df[\"loss\"].apply(sum)\n",
    "df_tmp = df.sort_values(by=\"total_loss\", ascending=False).head(3)\n",
    "\n",
    "for sample in get_samples(df_tmp):\n",
    "    display(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁Ham</td>\n",
       "      <td>a</td>\n",
       "      <td>▁(</td>\n",
       "      <td>▁Unternehmen</td>\n",
       "      <td>▁)</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-ORG</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>I-ORG</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>2.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.61</td>\n",
       "      <td>2.33</td>\n",
       "      <td>2.61</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0     1      2             3      4     5\n",
       "tokens   ▁Ham     a     ▁(  ▁Unternehmen     ▁)  </s>\n",
       "labels  B-ORG   IGN  I-ORG         I-ORG  I-ORG   IGN\n",
       "preds       O     O      O             O      O     O\n",
       "losses   2.57  0.00   2.61          2.33   2.61  0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>tokens</th>\n",
       "      <td>▁Kesk</td>\n",
       "      <td>kül</td>\n",
       "      <td>a</td>\n",
       "      <td>▁(</td>\n",
       "      <td>▁Mart</td>\n",
       "      <td>na</td>\n",
       "      <td>▁)</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>labels</th>\n",
       "      <td>B-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "      <td>I-LOC</td>\n",
       "      <td>IGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>preds</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>losses</th>\n",
       "      <td>2.40</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.90</td>\n",
       "      <td>2.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.97</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            0     1     2      3      4     5      6     7\n",
       "tokens  ▁Kesk   kül     a     ▁(  ▁Mart    na     ▁)  </s>\n",
       "labels  B-LOC   IGN   IGN  I-LOC  I-LOC   IGN  I-LOC   IGN\n",
       "preds       O     O     O      O      O     O      O     O\n",
       "losses   2.40  0.00  0.00   2.90   2.70  0.00   2.97  0.00"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_tmp = df.loc[df[\"input_tokens\"].apply(lambda x: u\"\\u2581(\" in x)].head(2)\n",
    "for sample in get_samples(df_tmp):\n",
    "    display(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_f1_score(trainer, dataset):\n",
    "    return trainer.predict(dataset).metrics[\"test_f1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de] model on [de] dataset: 0.000\n"
     ]
    }
   ],
   "source": [
    "f1_scores = defaultdict(dict)\n",
    "f1_scores[\"de\"][\"de\"] = get_f1_score(trainer, panx_de_encoded[\"test\"])\n",
    "print(f\"F1-score of [de] model on [de] dataset: {f1_scores['de']['de']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Tokens</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>▁Jeff</td>\n",
       "      <td>▁De</td>\n",
       "      <td>an</td>\n",
       "      <td>▁est</td>\n",
       "      <td>▁informatic</td>\n",
       "      <td>ien</td>\n",
       "      <td>▁chez</td>\n",
       "      <td>▁Google</td>\n",
       "      <td>▁en</td>\n",
       "      <td>▁Cali</td>\n",
       "      <td>for</td>\n",
       "      <td>nie</td>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tags</th>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "      <td>O</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0      1    2   3     4            5    6      7        8    9   \\\n",
       "Tokens  <s>  ▁Jeff  ▁De  an  ▁est  ▁informatic  ien  ▁chez  ▁Google  ▁en   \n",
       "Tags      O      O    O   O     O            O    O      O        O    O   \n",
       "\n",
       "           10   11   12    13  \n",
       "Tokens  ▁Cali  for  nie  </s>  \n",
       "Tags        O    O    O     O  "
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_fr = \"Jeff Dean est informaticien chez Google en Californie\"\n",
    "tag_text(text_fr, tags, trainer.model, xlmr_tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_lang_performance(lang, trainer):\n",
    "    panx_ds = encode_panx_dataset(panx_ch[lang])\n",
    "    return get_f1_score(trainer, panx_ds[\"test\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cff086e0b1714311ba034076ab6729d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2290 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de] model on [fr] dataset: 0.000\n"
     ]
    }
   ],
   "source": [
    "f1_scores[\"de\"][\"fr\"] = evaluate_lang_performance(\"fr\", trainer)\n",
    "print(f\"F1-score of [de] model on [fr] dataset: {f1_scores['de']['fr']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de] model on [it] dataset: 0.000\n"
     ]
    }
   ],
   "source": [
    "f1_scores[\"de\"][\"it\"] = evaluate_lang_performance(\"it\", trainer)\n",
    "print(f\"F1-score of [de] model on [it] dataset: {f1_scores['de']['it']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1-score of [de] model on [en] dataset: 0.000\n"
     ]
    }
   ],
   "source": [
    "f1_scores[\"de\"][\"en\"] = evaluate_lang_performance(\"en\", trainer)\n",
    "print(f\"F1-score of [de] model on [en] dataset: {f1_scores['de']['en']:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_on_subset(dataset, num_samples):\n",
    "    train_ds = dataset[\"train\"].shuffle(seed=42).select(range(num_samples))\n",
    "    valid_ds = dataset[\"validation\"]\n",
    "    test_ds = dataset[\"test\"]\n",
    "    training_args.logging_steps = len(train_ds) // batch_size\n",
    "\n",
    "    trainer = Trainer(model_init=model_init, args=training_args,\n",
    "        data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "        train_dataset=train_ds, eval_dataset=valid_ds, tokenizer=xlmr_tokenizer)\n",
    "    trainer.train()\n",
    "    if training_args.push_to_hub:\n",
    "        trainer.push_to_hub(commit_message=\"Training completed!\")\n",
    "\n",
    "    f1_score = get_f1_score(trainer, test_ds)\n",
    "    return pd.DataFrame.from_dict(\n",
    "        {\"num_samples\": [len(train_ds)], \"f1_score\": [f1_score]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "panx_fr_encoded = encode_panx_dataset(panx_ch[\"fr\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='34' max='33' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [33/33 01:19, Epoch 3/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1.977100</td>\n",
       "      <td>1.957699</td>\n",
       "      <td>0.017944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1.954100</td>\n",
       "      <td>1.948463</td>\n",
       "      <td>0.019541</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='51' max='96' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [51/96 00:16 < 00:14, 3.09 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[168], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m training_args\u001b[38;5;241m.\u001b[39mpush_to_hub \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m metrics_df \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_on_subset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpanx_fr_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m250\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m metrics_df\n",
      "Cell \u001b[0;32mIn[166], line 10\u001b[0m, in \u001b[0;36mtrain_on_subset\u001b[0;34m(dataset, num_samples)\u001b[0m\n\u001b[1;32m      5\u001b[0m training_args\u001b[38;5;241m.\u001b[39mlogging_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(train_ds) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m batch_size\n\u001b[1;32m      7\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model_init\u001b[38;5;241m=\u001b[39mmodel_init, args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m      8\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator, compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m      9\u001b[0m     train_dataset\u001b[38;5;241m=\u001b[39mtrain_ds, eval_dataset\u001b[38;5;241m=\u001b[39mvalid_ds, tokenizer\u001b[38;5;241m=\u001b[39mxlmr_tokenizer)\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m training_args\u001b[38;5;241m.\u001b[39mpush_to_hub:\n\u001b[1;32m     12\u001b[0m     trainer\u001b[38;5;241m.\u001b[39mpush_to_hub(commit_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/git/ml-notebooks/.venv/lib/python3.11/site-packages/transformers/trainer.py:1537\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1535\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1536\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1537\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1538\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1539\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1540\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1541\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1542\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/ml-notebooks/.venv/lib/python3.11/site-packages/transformers/trainer.py:1929\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1926\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol\u001b[38;5;241m.\u001b[39mshould_training_stop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m   1928\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_epoch_end(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[0;32m-> 1929\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_maybe_log_save_evaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepoch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1931\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m DebugOption\u001b[38;5;241m.\u001b[39mTPU_METRICS_DEBUG \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdebug:\n\u001b[1;32m   1932\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_torch_tpu_available():\n\u001b[1;32m   1933\u001b[0m         \u001b[38;5;66;03m# tpu-comment: Logging debug metrics for PyTorch/XLA (compile, execute times, ops, etc.)\u001b[39;00m\n",
      "File \u001b[0;32m~/git/ml-notebooks/.venv/lib/python3.11/site-packages/transformers/trainer.py:2268\u001b[0m, in \u001b[0;36mTrainer._maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   2266\u001b[0m         metrics\u001b[38;5;241m.\u001b[39mupdate(dataset_metrics)\n\u001b[1;32m   2267\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2268\u001b[0m     metrics \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2269\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_report_to_hp_search(trial, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step, metrics)\n\u001b[1;32m   2271\u001b[0m \u001b[38;5;66;03m# Run delayed LR scheduler now that metrics are populated\u001b[39;00m\n",
      "File \u001b[0;32m~/git/ml-notebooks/.venv/lib/python3.11/site-packages/transformers/trainer.py:3019\u001b[0m, in \u001b[0;36mTrainer.evaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3016\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n\u001b[1;32m   3018\u001b[0m eval_loop \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprediction_loop \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39muse_legacy_prediction_loop \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mevaluation_loop\n\u001b[0;32m-> 3019\u001b[0m output \u001b[38;5;241m=\u001b[39m \u001b[43meval_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   3020\u001b[0m \u001b[43m    \u001b[49m\u001b[43meval_dataloader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3021\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdescription\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEvaluation\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3022\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# No point gathering the predictions if there are no metrics, otherwise we defer to\u001b[39;49;00m\n\u001b[1;32m   3023\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# self.args.prediction_loss_only\u001b[39;49;00m\n\u001b[1;32m   3024\u001b[0m \u001b[43m    \u001b[49m\u001b[43mprediction_loss_only\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_metrics\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   3025\u001b[0m \u001b[43m    \u001b[49m\u001b[43mignore_keys\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3026\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetric_key_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   3027\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3029\u001b[0m total_batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39meval_batch_size \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mworld_size\n\u001b[1;32m   3030\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmetric_key_prefix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_jit_compilation_time\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m output\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/git/ml-notebooks/.venv/lib/python3.11/site-packages/transformers/trainer.py:3220\u001b[0m, in \u001b[0;36mTrainer.evaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m   3218\u001b[0m     losses_host \u001b[38;5;241m=\u001b[39m losses \u001b[38;5;28;01mif\u001b[39;00m losses_host \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m nested_concat(losses_host, losses, padding_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m)\n\u001b[1;32m   3219\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 3220\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maccelerator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpad_across_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3221\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_decode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   3222\u001b[0m     inputs_decode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39mpad_across_processes(inputs_decode, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m, pad_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m100\u001b[39m)\n",
      "File \u001b[0;32m~/git/ml-notebooks/.venv/lib/python3.11/site-packages/accelerate/accelerator.py:2233\u001b[0m, in \u001b[0;36mAccelerator.pad_across_processes\u001b[0;34m(self, tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m   2200\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpad_across_processes\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, pad_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m, pad_first\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[1;32m   2201\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   2202\u001b[0m \u001b[38;5;124;03m    Recursively pad the tensors in a nested list/tuple/dictionary of tensors from all devices to the same size so\u001b[39;00m\n\u001b[1;32m   2203\u001b[0m \u001b[38;5;124;03m    they can safely be gathered.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   2231\u001b[0m \u001b[38;5;124;03m    ```\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 2233\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpad_across_processes\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_first\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/ml-notebooks/.venv/lib/python3.11/site-packages/accelerate/utils/operations.py:379\u001b[0m, in \u001b[0;36mchained_operation.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(function)\n\u001b[1;32m    377\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapper\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    378\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 379\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    380\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m DistributedOperationException \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    381\u001b[0m         operation \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__module__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunction\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/git/ml-notebooks/.venv/lib/python3.11/site-packages/accelerate/utils/operations.py:588\u001b[0m, in \u001b[0;36mpad_across_processes\u001b[0;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m    585\u001b[0m     new_tensor[indices] \u001b[38;5;241m=\u001b[39m tensor\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_tensor\n\u001b[0;32m--> 588\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mrecursively_apply\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_pad_across_processes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror_on_other_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_index\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_index\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpad_first\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpad_first\u001b[49m\n\u001b[1;32m    590\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/git/ml-notebooks/.venv/lib/python3.11/site-packages/accelerate/utils/operations.py:129\u001b[0m, in \u001b[0;36mrecursively_apply\u001b[0;34m(func, data, test_type, error_on_other_type, *args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(data)(\n\u001b[1;32m    121\u001b[0m         {\n\u001b[1;32m    122\u001b[0m             k: recursively_apply(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    126\u001b[0m         }\n\u001b[1;32m    127\u001b[0m     )\n\u001b[1;32m    128\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m test_type(data):\n\u001b[0;32m--> 129\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m error_on_other_type:\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    132\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnsupported types (\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mtype\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) passed to `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfunc\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m`. Only nested list/tuple/dicts of \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    133\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobjects that are valid for `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtest_type\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` should be passed.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m     )\n",
      "File \u001b[0;32m~/git/ml-notebooks/.venv/lib/python3.11/site-packages/accelerate/utils/operations.py:568\u001b[0m, in \u001b[0;36mpad_across_processes.<locals>._pad_across_processes\u001b[0;34m(tensor, dim, pad_index, pad_first)\u001b[0m\n\u001b[1;32m    565\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n\u001b[1;32m    567\u001b[0m \u001b[38;5;66;03m# Gather all sizes\u001b[39;00m\n\u001b[0;32m--> 568\u001b[0m size \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshape\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[1;32m    569\u001b[0m sizes \u001b[38;5;241m=\u001b[39m gather(size)\u001b[38;5;241m.\u001b[39mcpu()\n\u001b[1;32m    570\u001b[0m \u001b[38;5;66;03m# Then pad to the maximum size\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_args.push_to_hub = False\n",
    "metrics_df = train_on_subset(panx_fr_encoded, 250)\n",
    "metrics_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import concatenate_datasets\n",
    "\n",
    "def concatenate_splits(corpora):\n",
    "    multi_corpus = DatasetDict()\n",
    "    for split in corpora[0].keys():\n",
    "        multi_corpus[split] = concatenate_datasets(\n",
    "            [corpus[split] for corpus in corpora]).shuffle(seed=42)\n",
    "    return multi_corpus\n",
    "panx_de_fr_encoded = concatenate_splits([panx_de_encoded, panx_fr_encoded])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='111' max='2145' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 111/2145 06:54 < 2:08:53, 0.26 it/s, Epoch 0.15/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[69], line 10\u001b[0m\n\u001b[1;32m      3\u001b[0m training_args\u001b[38;5;241m.\u001b[39moutput_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mxlm-roberta-base-finetuned-panx-de-fr\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      5\u001b[0m trainer \u001b[38;5;241m=\u001b[39m Trainer(model_init\u001b[38;5;241m=\u001b[39mmodel_init, args\u001b[38;5;241m=\u001b[39mtraining_args,\n\u001b[1;32m      6\u001b[0m     data_collator\u001b[38;5;241m=\u001b[39mdata_collator, compute_metrics\u001b[38;5;241m=\u001b[39mcompute_metrics,\n\u001b[1;32m      7\u001b[0m     tokenizer\u001b[38;5;241m=\u001b[39mxlmr_tokenizer, train_dataset\u001b[38;5;241m=\u001b[39mpanx_de_fr_encoded[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m      8\u001b[0m     eval_dataset\u001b[38;5;241m=\u001b[39mpanx_de_fr_encoded[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalidation\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m---> 10\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m trainer\u001b[38;5;241m.\u001b[39mpush_to_hub(commit_message\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTraining completed!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/git/ml-notebooks/.venv/lib/python3.11/site-packages/transformers/trainer.py:1528\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1526\u001b[0m     \u001b[38;5;66;03m# Disable progress bars when uploading models during checkpoints to avoid polluting stdout\u001b[39;00m\n\u001b[1;32m   1527\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39mdisable_progress_bars()\n\u001b[0;32m-> 1528\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43minner_training_loop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1530\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mresume_from_checkpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1531\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrial\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1532\u001b[0m \u001b[43m        \u001b[49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mignore_keys_for_eval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1533\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1534\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m   1535\u001b[0m     hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n",
      "File \u001b[0;32m~/git/ml-notebooks/.venv/lib/python3.11/site-packages/transformers/trainer.py:1859\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1853\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[1;32m   1854\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1856\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1857\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1858\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[0;32m-> 1859\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misinf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtr_loss_step\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m   1860\u001b[0m ):\n\u001b[1;32m   1861\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1862\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n\u001b[1;32m   1863\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "training_args.logging_steps = len(panx_de_fr_encoded[\"train\"]) // batch_size\n",
    "training_args.push_to_hub = True\n",
    "training_args.output_dir = \"xlm-roberta-base-headtuned-panx-de-fr\"\n",
    "\n",
    "trainer = Trainer(model_init=model_init, args=training_args,\n",
    "    data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "    tokenizer=xlmr_tokenizer, train_dataset=panx_de_fr_encoded[\"train\"],\n",
    "    eval_dataset=panx_de_fr_encoded[\"validation\"])\n",
    "\n",
    "trainer.train()\n",
    "trainer.push_to_hub(commit_message=\"Training completed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for lang in langs:\n",
    "    f1 = evaluate_lang_performance(lang, trainer)\n",
    "    print(f\"F1-score of [de-fr] model on [{lang}] dataset: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora = [panx_de_encoded]\n",
    "\n",
    "# Exclude German from iteration\n",
    "for lang in langs[1:]:\n",
    "    training_args.output_dir = f\"xlm-roberta-base-headtuned-panx-{lang}\"\n",
    "    # Fine-tune on monolingual corpus\n",
    "    ds_encoded = encode_panx_dataset(panx_ch[lang])\n",
    "    metrics = train_on_subset(ds_encoded, ds_encoded[\"train\"].num_rows)\n",
    "    # Collect F1-scores in common dict\n",
    "    f1_scores[lang][lang] = metrics[\"f1_score\"][0]\n",
    "    # Add monolingual corpus to list of corpora to concatenate\n",
    "    corpora.append(ds_encoded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpora_encoded = concatenate_splits(corpora)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args.logging_steps = len(corpora_encoded[\"train\"]) // batch_size\n",
    "training_args.output_dir = \"xlm-roberta-base-headtuned-panx-all\"\n",
    "\n",
    "trainer = Trainer(model_init=model_init, args=training_args,\n",
    "    data_collator=data_collator, compute_metrics=compute_metrics,\n",
    "    tokenizer=xlmr_tokenizer, train_dataset=corpora_encoded[\"train\"],\n",
    "    eval_dataset=corpora_encoded[\"validation\"])\n",
    "\n",
    "trainer.train()\n",
    "trainer.push_to_hub(commit_message=\"Training completed!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
